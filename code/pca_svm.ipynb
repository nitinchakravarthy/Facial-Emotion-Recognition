{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pca_svm.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"22Xv6JqpaUjO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":74},"outputId":"9608705b-d4a1-49e3-ed88-ad8b420df392","executionInfo":{"status":"ok","timestamp":1543695547235,"user_tz":360,"elapsed":1668,"user":{"displayName":"Venkata Nitin Chakravarthy Gummidela","photoUrl":"","userId":"12388962152434948445"}}},"cell_type":"code","source":["import cv2\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","from skimage import io\n","from sklearn.cross_validation import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","    \n","import sklearn\n","from sklearn import preprocessing\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn import metrics\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.svm import SVC\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n","  \"This module will be removed in 0.20.\", DeprecationWarning)\n"],"name":"stderr"}]},{"metadata":{"id":"lIrBHX04aUje","colab_type":"code","colab":{}},"cell_type":"code","source":["def create_data_set(): \n","    images_path = [ os.path.join(\"yalefaces\", item)  for item in  os.listdir(\"yalefaces\") ]\n","    image_data = []\n","    person_labels = []\n","    setting_labels = []\n","    \n","    for i,im_path in enumerate(images_path):\n","        im = io.imread(im_path,as_grey=True)\n","#         print(im_path)\n","#         io.imshow(im)\n","#         io.show()\n","        image_data.append(np.array(im, dtype='uint8'))\n","    \n","        person_label = int(os.path.split(im_path)[1].split(\".\")[0].replace(\"subject\", \"\")) -1\n","        setting_label = os.path.split(im_path)[1].split(\".\")[1]\n","\n","#         print(setting_label)\n","        person_labels.append(person_label)\n","        setting_labels.append(setting_label)\n","    return image_data, person_labels, setting_labels\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uDwgNow2aUjl","colab_type":"code","colab":{},"outputId":"77474bea-8d5d-4f73-fe31-ff6a817978d5"},"cell_type":"code","source":["x, y, dummy = create_data_set()\n","\n","# reshaping\n","x = np.array(x)\n","y = np.array(y)\n","\n","\n","x_flat = np.reshape(x,(x.shape[0],77760))\n","\n","x_norm = []\n","\n","## normalizing the image for PCA\n","for i,image in enumerate(x):\n","#     print(i)\n","    image = StandardScaler().fit_transform(image)\n","    x_norm.append(np.array(image, dtype='uint8'))\n","    \n","x_norm = np.array(x_norm)\n","x_flat_norm = np.reshape(x_norm,(x_norm.shape[0],77760))\n","x_flat_norm = np.array(x_flat_norm)\n","\n","print(x.shape)\n","print(y.shape)\n","print(x_flat_norm.shape)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["C:\\Users\\tintin\\Anaconda3\\lib\\site-packages\\skimage\\io\\_io.py:49: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n","  warn('`as_grey` has been deprecated in favor of `as_gray`')\n","C:\\Users\\tintin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n","  warnings.warn(msg, DataConversionWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["(165, 243, 320)\n","(165,)\n","(165, 77760)\n"],"name":"stdout"}]},{"metadata":{"id":"MvvlekIQaUjv","colab_type":"code","colab":{},"outputId":"182fbb42-637c-4c8d-8318-fc294304cb98"},"cell_type":"code","source":["# svm predictor\n","\n","## Cross validation to find num of components\n","num_of_components = [1,5,10,20,30,40,50]\n","index=0;\n","acc_array = []\n","count = 0\n","\n","# finding the best params for SVC with RBF kernel\n","Cs= [1e3, 5e3, 1e4, 5e4, 1e5]\n","gammas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]\n","\n","# outer 5fold CV\n","kf_out = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 50)\n","# test train split\n","for train, test in kf_out.split(x_flat_norm, y):\n","        x_train, x_test = x_flat_norm[train], x_flat_norm[test]\n","        y_train, y_test = y[train], y[test]\n","#         print(x_train.shape)\n","#         print(y_train.shape)\n","#         print(y_train)\n","        # inner 5-fold CV\n","        fold =0\n","        max_acc = 0\n","        best_comp = 0\n","        best_C=0\n","        best_gamma=0\n","        for x in num_of_components:\n","#             print(x)\n","#             print(len(Cs))\n","#             print(len(gammas))\n","            for c_index in range(0,len(Cs)):\n","                for gamma_index in range(0,len(gammas)):\n","                    temp_acc_splits = []\n","                    kf_in = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 50)\n","                    for train_in, val in kf_in.split(x_train, y_train):\n","                        fold += 1\n","                        x_train_in, x_val = x_flat_norm[train_in], x_flat_norm[val]\n","                        y_train_in, y_val = y[train_in], y[val]   \n","            #             print(x_train_in.shape)\n","            #             print(x_val.shape) \n","                        components = x\n","                        pca_in = PCA(n_components=components, whiten=True)\n","                        pca_in.fit(x_train_in)\n","                        x_train_in_pca = pca_in.transform(x_train_in)\n","                        x_val_pca = pca_in.transform(x_val)\n","                        clf = SVC(kernel='rbf',gamma=gammas[gamma_index], C = Cs[c_index])\n","#                         clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=d))\n","                        clf = clf.fit(x_train_in_pca, y_train_in)\n","                        y_pred = clf.predict(x_val_pca)\n","                        acc = metrics.accuracy_score(y_val, y_pred)\n","                        temp_acc_splits.append(acc)\n","                    accuracy_mean_splits = np.mean(np.array(temp_acc_splits))\n","                    if accuracy_mean_splits>max_acc:\n","                        max_acc=accuracy_mean_splits\n","                        best_comp = components\n","                        best_C= Cs[c_index]\n","                        best_gamma = gammas[gamma_index]\n","    #                 print(\" Number of Components :\",components , \"best depth is \", best_depth ,\" and best Accuracy :\",max_acc)\n","\n","        # Now that we got the best model for each component from the inner CV use that on the test data\n","        print(best_comp)\n","        print(best_C)\n","        print(best_gamma)\n","        pca_out = PCA(n_components= best_comp, whiten=True)\n","        pca_out = pca_out.fit(x_train)\n","        x_train_pca = pca_out.transform(x_train)\n","#         print(x_train)\n","        x_test_pca = pca_out.transform(x_test)\n","        svc_out = SVC(kernel='rbf',gamma=best_gamma, C = best_C)\n","#         abc_out = AdaBoostClassifier(DecisionTreeClassifier(max_depth=best_depth))\n","#         print(y_train)\n","#         print(x_train_pca)\n","        svc_out = svc_out.fit(x_train_pca,y_train)\n","        y_pred_out = svc_out.predict(x_test_pca)\n","        acc_array.append(accuracy_score(y_test, y_pred_out))\n","        count +=1\n","        print(\"classification report in fold\", count )\n","        print(metrics.classification_report(y_test, y_pred_out))\n","        \n","        \n","print(\"Average accuracy : \", np.mean(acc_array))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["40\n","10000.0\n","0.0005\n","classification report in fold 1\n","             precision    recall  f1-score   support\n","\n","          0       1.00      1.00      1.00         3\n","          1       1.00      1.00      1.00         3\n","          2       0.75      1.00      0.86         3\n","          3       1.00      1.00      1.00         3\n","          4       1.00      1.00      1.00         3\n","          5       1.00      1.00      1.00         3\n","          6       1.00      1.00      1.00         3\n","          7       1.00      0.67      0.80         3\n","          8       1.00      1.00      1.00         3\n","          9       1.00      1.00      1.00         3\n","         10       1.00      1.00      1.00         3\n","         11       1.00      1.00      1.00         3\n","         12       1.00      1.00      1.00         3\n","         13       1.00      1.00      1.00         3\n","         14       1.00      1.00      1.00         3\n","\n","avg / total       0.98      0.98      0.98        45\n","\n","30\n","1000.0\n","0.0001\n","classification report in fold 2\n","             precision    recall  f1-score   support\n","\n","          0       1.00      0.50      0.67         2\n","          1       1.00      1.00      1.00         2\n","          2       0.50      1.00      0.67         2\n","          3       1.00      1.00      1.00         2\n","          4       1.00      1.00      1.00         2\n","          5       1.00      1.00      1.00         2\n","          6       1.00      1.00      1.00         2\n","          7       1.00      1.00      1.00         2\n","          8       1.00      1.00      1.00         2\n","          9       1.00      1.00      1.00         2\n","         10       1.00      1.00      1.00         2\n","         11       1.00      1.00      1.00         2\n","         12       1.00      1.00      1.00         2\n","         13       1.00      1.00      1.00         2\n","         14       1.00      0.50      0.67         2\n","\n","avg / total       0.97      0.93      0.93        30\n","\n","30\n","1000.0\n","0.005\n","classification report in fold 3\n","             precision    recall  f1-score   support\n","\n","          0       1.00      0.50      0.67         2\n","          1       0.67      1.00      0.80         2\n","          2       1.00      1.00      1.00         2\n","          3       1.00      1.00      1.00         2\n","          4       1.00      1.00      1.00         2\n","          5       1.00      1.00      1.00         2\n","          6       1.00      1.00      1.00         2\n","          7       1.00      1.00      1.00         2\n","          8       1.00      1.00      1.00         2\n","          9       1.00      1.00      1.00         2\n","         10       1.00      1.00      1.00         2\n","         11       1.00      1.00      1.00         2\n","         12       1.00      1.00      1.00         2\n","         13       1.00      1.00      1.00         2\n","         14       1.00      1.00      1.00         2\n","\n","avg / total       0.98      0.97      0.96        30\n","\n","30\n","1000.0\n","0.005\n","classification report in fold 4\n","             precision    recall  f1-score   support\n","\n","          0       1.00      0.50      0.67         2\n","          1       1.00      1.00      1.00         2\n","          2       1.00      0.50      0.67         2\n","          3       1.00      0.50      0.67         2\n","          4       1.00      0.50      0.67         2\n","          5       1.00      1.00      1.00         2\n","          6       0.20      1.00      0.33         2\n","          7       0.67      1.00      0.80         2\n","          8       0.00      0.00      0.00         2\n","          9       1.00      0.50      0.67         2\n","         10       1.00      1.00      1.00         2\n","         11       1.00      1.00      1.00         2\n","         12       1.00      0.50      0.67         2\n","         13       1.00      1.00      1.00         2\n","         14       1.00      0.50      0.67         2\n","\n","avg / total       0.86      0.70      0.72        30\n","\n"],"name":"stdout"},{"output_type":"stream","text":["C:\\Users\\tintin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"},{"output_type":"stream","text":["50\n","1000.0\n","0.0001\n","classification report in fold 5\n","             precision    recall  f1-score   support\n","\n","          0       1.00      1.00      1.00         2\n","          1       1.00      1.00      1.00         2\n","          2       1.00      1.00      1.00         2\n","          3       1.00      1.00      1.00         2\n","          4       1.00      1.00      1.00         2\n","          5       1.00      1.00      1.00         2\n","          6       1.00      1.00      1.00         2\n","          7       1.00      1.00      1.00         2\n","          8       1.00      1.00      1.00         2\n","          9       1.00      1.00      1.00         2\n","         10       1.00      1.00      1.00         2\n","         11       1.00      1.00      1.00         2\n","         12       1.00      1.00      1.00         2\n","         13       1.00      1.00      1.00         2\n","         14       1.00      1.00      1.00         2\n","\n","avg / total       1.00      1.00      1.00        30\n","\n","Average accuracy :  0.9155555555555555\n"],"name":"stdout"}]},{"metadata":{"id":"bjrfl_c9aUj3","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}