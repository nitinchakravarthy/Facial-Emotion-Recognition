{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "try_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "b6ULbTvWLz7q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adadelta,Adam\n",
        "\n",
        "\n",
        "#from keras.preprocessing import sequence\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1h0VZPaJZVD",
        "colab_type": "code",
        "outputId": "b723ce71-5191-44ff-8522-464049b36065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "with open(\"fer2013.csv\") as f:\n",
        "  content = f.readlines()\n",
        "  lines = np.array(content)\n",
        "\n",
        "  x_train, y_train, x_test, y_test = [], [], [], []\n",
        "  x_val, y_val = [], []\n",
        " \n",
        "  for i in range(1,lines.size):\n",
        "    try:\n",
        "      emotion_label, img_data, usage_type = lines[i].split(\",\")\n",
        "      pxl_val = img_data.split(\" \")\n",
        "      pixels = np.array(pxl_val, 'float32') \n",
        "      emotion_label = keras.utils.to_categorical(emotion_label, num_classes)\n",
        "      \n",
        "      if 'Training' in usage_type:\n",
        "        y_train.append(emotion_label)\n",
        "        x_train.append(pixels)\n",
        "      elif 'PublicTest' in usage_type:\n",
        "        y_test.append(emotion_label)\n",
        "        x_test.append(pixels)\n",
        "      elif 'PrivateTest' in usage_type:\n",
        "    except:\n",
        "      print(\"\", end=\"\")\n",
        "\n",
        "\n",
        "x_train = np.array(x_train, 'float32')\n",
        "y_train = np.array(y_train, 'float32')\n",
        "x_test = np.array(x_test, 'float32')\n",
        "y_test = np.array(y_test, 'float32')\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "x_train /= 255 #normalize inputs between [0, 1]\n",
        "x_test /= 255\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709, 2304)\n",
            "(3589, 2304)\n",
            "(28709, 7)\n",
            "(3589, 7)\n",
            "(28709, 48, 48, 1)\n",
            "(3589, 48, 48, 1)\n",
            "(28709, 7)\n",
            "(3589, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qjP7HsfRfuSt",
        "colab_type": "code",
        "outputId": "34d55f5a-2c35-43f5-9a5b-6f26ef61387e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.optimizers import Adadelta\n",
        "\n",
        "img_rows, img_cols = 48, 48\n",
        "num_classes = 7\n",
        "model = Sequential()\n",
        "\n",
        "#convolution layers\n",
        "model.add(Conv2D(12, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "#model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "#model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "#model.add(AveragePooling2D(pool_size=(3,3)`, strides=(2, 2)))\n",
        "\n",
        "#model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "#model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected layers\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "ada = Adadelta(lr=0.1, rho=0.95, epsilon=1e-07)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=ada,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 44, 44, 12)        312       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 22, 22, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 18, 18, 32)        9632      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 9, 9, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 2592)              0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 2048)              5310464   \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 7)                 1799      \n",
            "=================================================================\n",
            "Total params: 5,846,751\n",
            "Trainable params: 5,846,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EkG2G35N0uCC",
        "colab_type": "code",
        "outputId": "05383e3e-2026-4765-eadf-24a9ca8f4a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6225
        }
      },
      "cell_type": "code",
      "source": [
        "    batch_size=300\n",
        "    epochs=180 #changed from 30 to 70\n",
        "    model.fit(np.array(x_train), np.array(y_train), batch_size=batch_size,epochs=epochs,validation_split=0.1,verbose=1)\n",
        "    scores = model.evaluate(np.array(x_test), np.array(y_test), batch_size=batch_size)\n",
        "    print(\"Loss: \" + str(scores[0]))\n",
        "    print(\"Accuracy: \" + str(scores[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25838 samples, validate on 2871 samples\n",
            "Epoch 1/180\n",
            "25838/25838 [==============================] - 3s 119us/step - loss: 1.5238 - acc: 0.4159 - val_loss: 1.4775 - val_acc: 0.4385\n",
            "Epoch 2/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 1.5069 - acc: 0.4228 - val_loss: 1.4706 - val_acc: 0.4424\n",
            "Epoch 3/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.4945 - acc: 0.4262 - val_loss: 1.5091 - val_acc: 0.4256\n",
            "Epoch 4/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.4787 - acc: 0.4332 - val_loss: 1.4582 - val_acc: 0.4364\n",
            "Epoch 5/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.4642 - acc: 0.4389 - val_loss: 1.4497 - val_acc: 0.4357\n",
            "Epoch 6/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.4517 - acc: 0.4404 - val_loss: 1.4139 - val_acc: 0.4552\n",
            "Epoch 7/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.4384 - acc: 0.4477 - val_loss: 1.4686 - val_acc: 0.4270\n",
            "Epoch 8/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.4266 - acc: 0.4529 - val_loss: 1.4876 - val_acc: 0.4232\n",
            "Epoch 9/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 1.4137 - acc: 0.4584 - val_loss: 1.4197 - val_acc: 0.4514\n",
            "Epoch 10/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 1.3977 - acc: 0.4640 - val_loss: 1.4157 - val_acc: 0.4451\n",
            "Epoch 11/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.3863 - acc: 0.4710 - val_loss: 1.4287 - val_acc: 0.4451\n",
            "Epoch 12/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.3722 - acc: 0.4734 - val_loss: 1.4223 - val_acc: 0.4514\n",
            "Epoch 13/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.3595 - acc: 0.4830 - val_loss: 1.3622 - val_acc: 0.4706\n",
            "Epoch 14/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.3489 - acc: 0.4892 - val_loss: 1.3412 - val_acc: 0.4796\n",
            "Epoch 15/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.3349 - acc: 0.4899 - val_loss: 1.3682 - val_acc: 0.4633\n",
            "Epoch 16/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.3253 - acc: 0.4974 - val_loss: 1.3656 - val_acc: 0.4667\n",
            "Epoch 17/180\n",
            "25838/25838 [==============================] - 3s 117us/step - loss: 1.3132 - acc: 0.5014 - val_loss: 1.3393 - val_acc: 0.4716\n",
            "Epoch 18/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.2960 - acc: 0.5091 - val_loss: 1.4034 - val_acc: 0.4552\n",
            "Epoch 19/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.2849 - acc: 0.5163 - val_loss: 1.3318 - val_acc: 0.4838\n",
            "Epoch 20/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.2716 - acc: 0.5187 - val_loss: 1.3704 - val_acc: 0.4786\n",
            "Epoch 21/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.2586 - acc: 0.5238 - val_loss: 1.2985 - val_acc: 0.4956\n",
            "Epoch 22/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.2498 - acc: 0.5300 - val_loss: 1.2961 - val_acc: 0.4908\n",
            "Epoch 23/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 1.2334 - acc: 0.5346 - val_loss: 1.3567 - val_acc: 0.4751\n",
            "Epoch 24/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.2261 - acc: 0.5381 - val_loss: 1.3665 - val_acc: 0.4570\n",
            "Epoch 25/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.2073 - acc: 0.5488 - val_loss: 1.3004 - val_acc: 0.4883\n",
            "Epoch 26/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.1986 - acc: 0.5543 - val_loss: 1.3117 - val_acc: 0.4977\n",
            "Epoch 27/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.1809 - acc: 0.5591 - val_loss: 1.2713 - val_acc: 0.5047\n",
            "Epoch 28/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 1.1673 - acc: 0.5656 - val_loss: 1.2831 - val_acc: 0.5023\n",
            "Epoch 29/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 1.1590 - acc: 0.5680 - val_loss: 1.2728 - val_acc: 0.5099\n",
            "Epoch 30/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.1349 - acc: 0.5767 - val_loss: 1.3312 - val_acc: 0.4835\n",
            "Epoch 31/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.1282 - acc: 0.5804 - val_loss: 1.2752 - val_acc: 0.5124\n",
            "Epoch 32/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.1123 - acc: 0.5880 - val_loss: 1.2565 - val_acc: 0.5169\n",
            "Epoch 33/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.1030 - acc: 0.5897 - val_loss: 1.2917 - val_acc: 0.5044\n",
            "Epoch 34/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 1.0842 - acc: 0.6005 - val_loss: 1.2684 - val_acc: 0.5127\n",
            "Epoch 35/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.0668 - acc: 0.6045 - val_loss: 1.3540 - val_acc: 0.4859\n",
            "Epoch 36/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 1.0545 - acc: 0.6135 - val_loss: 1.2700 - val_acc: 0.5138\n",
            "Epoch 37/180\n",
            "25838/25838 [==============================] - 3s 117us/step - loss: 1.0361 - acc: 0.6197 - val_loss: 1.2568 - val_acc: 0.5162\n",
            "Epoch 38/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.0257 - acc: 0.6240 - val_loss: 1.3612 - val_acc: 0.4890\n",
            "Epoch 39/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 1.0053 - acc: 0.6297 - val_loss: 1.2933 - val_acc: 0.5061\n",
            "Epoch 40/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.9856 - acc: 0.6388 - val_loss: 1.2391 - val_acc: 0.5270\n",
            "Epoch 41/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.9710 - acc: 0.6487 - val_loss: 1.2604 - val_acc: 0.5207\n",
            "Epoch 42/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.9590 - acc: 0.6492 - val_loss: 1.2784 - val_acc: 0.5155\n",
            "Epoch 43/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.9415 - acc: 0.6588 - val_loss: 1.2685 - val_acc: 0.5155\n",
            "Epoch 44/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.9287 - acc: 0.6624 - val_loss: 1.3908 - val_acc: 0.5064\n",
            "Epoch 45/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.9070 - acc: 0.6746 - val_loss: 1.2273 - val_acc: 0.5437\n",
            "Epoch 46/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.8928 - acc: 0.6792 - val_loss: 1.3229 - val_acc: 0.5158\n",
            "Epoch 47/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.8758 - acc: 0.6835 - val_loss: 1.3209 - val_acc: 0.5263\n",
            "Epoch 48/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.8542 - acc: 0.6927 - val_loss: 1.3872 - val_acc: 0.4991\n",
            "Epoch 49/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.8414 - acc: 0.6956 - val_loss: 1.3716 - val_acc: 0.5068\n",
            "Epoch 50/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.8244 - acc: 0.7037 - val_loss: 1.3430 - val_acc: 0.5127\n",
            "Epoch 51/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.8011 - acc: 0.7143 - val_loss: 1.3348 - val_acc: 0.5155\n",
            "Epoch 52/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.7765 - acc: 0.7247 - val_loss: 1.3571 - val_acc: 0.5225\n",
            "Epoch 53/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.7660 - acc: 0.7267 - val_loss: 1.4189 - val_acc: 0.5099\n",
            "Epoch 54/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.7376 - acc: 0.7389 - val_loss: 1.2783 - val_acc: 0.5444\n",
            "Epoch 55/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.7281 - acc: 0.7432 - val_loss: 1.3034 - val_acc: 0.5465\n",
            "Epoch 56/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.7168 - acc: 0.7481 - val_loss: 1.4445 - val_acc: 0.5152\n",
            "Epoch 57/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.6872 - acc: 0.7583 - val_loss: 1.3585 - val_acc: 0.5273\n",
            "Epoch 58/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.6761 - acc: 0.7619 - val_loss: 1.4933 - val_acc: 0.4772\n",
            "Epoch 59/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.6568 - acc: 0.7679 - val_loss: 1.5363 - val_acc: 0.5221\n",
            "Epoch 60/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.6311 - acc: 0.7807 - val_loss: 1.3659 - val_acc: 0.5249\n",
            "Epoch 61/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.6107 - acc: 0.7893 - val_loss: 1.4131 - val_acc: 0.5242\n",
            "Epoch 62/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.5942 - acc: 0.7930 - val_loss: 1.3234 - val_acc: 0.5521\n",
            "Epoch 63/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.5851 - acc: 0.7971 - val_loss: 1.4009 - val_acc: 0.5472\n",
            "Epoch 64/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.5637 - acc: 0.8042 - val_loss: 1.3792 - val_acc: 0.5374\n",
            "Epoch 65/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.5566 - acc: 0.8084 - val_loss: 1.4041 - val_acc: 0.5462\n",
            "Epoch 66/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.5191 - acc: 0.8244 - val_loss: 1.3946 - val_acc: 0.5451\n",
            "Epoch 67/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.5139 - acc: 0.8241 - val_loss: 1.3853 - val_acc: 0.5528\n",
            "Epoch 68/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.4920 - acc: 0.8331 - val_loss: 1.4265 - val_acc: 0.5357\n",
            "Epoch 69/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.4843 - acc: 0.8321 - val_loss: 1.5162 - val_acc: 0.5441\n",
            "Epoch 70/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.4608 - acc: 0.8453 - val_loss: 1.3590 - val_acc: 0.5569\n",
            "Epoch 71/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.4335 - acc: 0.8541 - val_loss: 1.4022 - val_acc: 0.5569\n",
            "Epoch 72/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.4387 - acc: 0.8532 - val_loss: 1.4450 - val_acc: 0.5580\n",
            "Epoch 73/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.4152 - acc: 0.8618 - val_loss: 1.6400 - val_acc: 0.5054\n",
            "Epoch 74/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.4010 - acc: 0.8671 - val_loss: 1.4858 - val_acc: 0.5388\n",
            "Epoch 75/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.3869 - acc: 0.8693 - val_loss: 1.4773 - val_acc: 0.5653\n",
            "Epoch 76/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.3636 - acc: 0.8803 - val_loss: 1.6308 - val_acc: 0.5402\n",
            "Epoch 77/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.3561 - acc: 0.8815 - val_loss: 1.6974 - val_acc: 0.5284\n",
            "Epoch 78/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.3315 - acc: 0.8911 - val_loss: 1.5197 - val_acc: 0.5594\n",
            "Epoch 79/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.3373 - acc: 0.8874 - val_loss: 1.5904 - val_acc: 0.5521\n",
            "Epoch 80/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.3122 - acc: 0.8988 - val_loss: 1.5510 - val_acc: 0.5587\n",
            "Epoch 81/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.3111 - acc: 0.8975 - val_loss: 1.5473 - val_acc: 0.5528\n",
            "Epoch 82/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.2969 - acc: 0.9046 - val_loss: 1.5719 - val_acc: 0.5618\n",
            "Epoch 83/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.2816 - acc: 0.9077 - val_loss: 1.5514 - val_acc: 0.5639\n",
            "Epoch 84/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.2690 - acc: 0.9133 - val_loss: 1.6278 - val_acc: 0.5468\n",
            "Epoch 85/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.2568 - acc: 0.9185 - val_loss: 1.6182 - val_acc: 0.5416\n",
            "Epoch 86/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.2459 - acc: 0.9211 - val_loss: 1.6604 - val_acc: 0.5594\n",
            "Epoch 87/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.2398 - acc: 0.9234 - val_loss: 1.7755 - val_acc: 0.5475\n",
            "Epoch 88/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.2322 - acc: 0.9269 - val_loss: 1.7268 - val_acc: 0.5594\n",
            "Epoch 89/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.2169 - acc: 0.9321 - val_loss: 1.7135 - val_acc: 0.5563\n",
            "Epoch 90/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.2075 - acc: 0.9350 - val_loss: 1.6946 - val_acc: 0.5587\n",
            "Epoch 91/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.1989 - acc: 0.9389 - val_loss: 1.6982 - val_acc: 0.5618\n",
            "Epoch 92/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.1968 - acc: 0.9385 - val_loss: 1.7686 - val_acc: 0.5549\n",
            "Epoch 93/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.1859 - acc: 0.9443 - val_loss: 1.7412 - val_acc: 0.5608\n",
            "Epoch 94/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.1772 - acc: 0.9467 - val_loss: 1.8741 - val_acc: 0.5462\n",
            "Epoch 95/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.1682 - acc: 0.9494 - val_loss: 1.7652 - val_acc: 0.5556\n",
            "Epoch 96/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1630 - acc: 0.9512 - val_loss: 1.7834 - val_acc: 0.5531\n",
            "Epoch 97/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1612 - acc: 0.9503 - val_loss: 1.8046 - val_acc: 0.5608\n",
            "Epoch 98/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1546 - acc: 0.9517 - val_loss: 1.8719 - val_acc: 0.5514\n",
            "Epoch 99/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.1517 - acc: 0.9534 - val_loss: 1.9097 - val_acc: 0.5597\n",
            "Epoch 100/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1425 - acc: 0.9589 - val_loss: 1.8108 - val_acc: 0.5566\n",
            "Epoch 101/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.1361 - acc: 0.9589 - val_loss: 2.0506 - val_acc: 0.5493\n",
            "Epoch 102/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1348 - acc: 0.9605 - val_loss: 1.9878 - val_acc: 0.5597\n",
            "Epoch 103/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.1301 - acc: 0.9609 - val_loss: 1.9639 - val_acc: 0.5559\n",
            "Epoch 104/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1232 - acc: 0.9634 - val_loss: 2.0089 - val_acc: 0.5538\n",
            "Epoch 105/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1174 - acc: 0.9657 - val_loss: 1.9383 - val_acc: 0.5576\n",
            "Epoch 106/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1100 - acc: 0.9679 - val_loss: 2.0490 - val_acc: 0.5556\n",
            "Epoch 107/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.1136 - acc: 0.9659 - val_loss: 1.9866 - val_acc: 0.5556\n",
            "Epoch 108/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.1108 - acc: 0.9667 - val_loss: 2.0555 - val_acc: 0.5664\n",
            "Epoch 109/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.1069 - acc: 0.9670 - val_loss: 1.9984 - val_acc: 0.5604\n",
            "Epoch 110/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.1032 - acc: 0.9700 - val_loss: 1.9950 - val_acc: 0.5636\n",
            "Epoch 111/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0942 - acc: 0.9718 - val_loss: 2.0703 - val_acc: 0.5601\n",
            "Epoch 112/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0967 - acc: 0.9714 - val_loss: 2.0478 - val_acc: 0.5472\n",
            "Epoch 113/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0893 - acc: 0.9748 - val_loss: 2.0202 - val_acc: 0.5622\n",
            "Epoch 114/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0906 - acc: 0.9742 - val_loss: 2.0992 - val_acc: 0.5535\n",
            "Epoch 115/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0896 - acc: 0.9739 - val_loss: 2.0385 - val_acc: 0.5608\n",
            "Epoch 116/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0880 - acc: 0.9741 - val_loss: 2.1004 - val_acc: 0.5622\n",
            "Epoch 117/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0789 - acc: 0.9776 - val_loss: 2.2856 - val_acc: 0.5444\n",
            "Epoch 118/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.0811 - acc: 0.9760 - val_loss: 2.0951 - val_acc: 0.5684\n",
            "Epoch 119/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0783 - acc: 0.9790 - val_loss: 2.1761 - val_acc: 0.5500\n",
            "Epoch 120/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0771 - acc: 0.9783 - val_loss: 2.2016 - val_acc: 0.5667\n",
            "Epoch 121/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0739 - acc: 0.9788 - val_loss: 2.2586 - val_acc: 0.5413\n",
            "Epoch 122/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.0771 - acc: 0.9784 - val_loss: 2.1414 - val_acc: 0.5618\n",
            "Epoch 123/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.0705 - acc: 0.9797 - val_loss: 2.2495 - val_acc: 0.5677\n",
            "Epoch 124/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0700 - acc: 0.9804 - val_loss: 2.2890 - val_acc: 0.5583\n",
            "Epoch 125/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.0687 - acc: 0.9808 - val_loss: 2.2406 - val_acc: 0.5615\n",
            "Epoch 126/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0669 - acc: 0.9816 - val_loss: 2.2336 - val_acc: 0.5583\n",
            "Epoch 127/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0627 - acc: 0.9821 - val_loss: 2.1953 - val_acc: 0.5632\n",
            "Epoch 128/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0655 - acc: 0.9814 - val_loss: 2.2133 - val_acc: 0.5646\n",
            "Epoch 129/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0594 - acc: 0.9832 - val_loss: 2.2068 - val_acc: 0.5657\n",
            "Epoch 130/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0640 - acc: 0.9815 - val_loss: 2.2425 - val_acc: 0.5629\n",
            "Epoch 131/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0600 - acc: 0.9823 - val_loss: 2.2779 - val_acc: 0.5622\n",
            "Epoch 132/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0595 - acc: 0.9833 - val_loss: 2.3020 - val_acc: 0.5657\n",
            "Epoch 133/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0592 - acc: 0.9837 - val_loss: 2.2677 - val_acc: 0.5670\n",
            "Epoch 134/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0550 - acc: 0.9854 - val_loss: 2.3638 - val_acc: 0.5587\n",
            "Epoch 135/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0546 - acc: 0.9846 - val_loss: 2.2763 - val_acc: 0.5611\n",
            "Epoch 136/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0558 - acc: 0.9844 - val_loss: 2.4048 - val_acc: 0.5597\n",
            "Epoch 137/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0524 - acc: 0.9858 - val_loss: 2.2902 - val_acc: 0.5563\n",
            "Epoch 138/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0527 - acc: 0.9852 - val_loss: 2.3426 - val_acc: 0.5643\n",
            "Epoch 139/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0487 - acc: 0.9861 - val_loss: 2.3215 - val_acc: 0.5670\n",
            "Epoch 140/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0498 - acc: 0.9866 - val_loss: 2.2714 - val_acc: 0.5691\n",
            "Epoch 141/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0522 - acc: 0.9839 - val_loss: 2.3402 - val_acc: 0.5705\n",
            "Epoch 142/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0478 - acc: 0.9866 - val_loss: 2.3450 - val_acc: 0.5698\n",
            "Epoch 143/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0446 - acc: 0.9879 - val_loss: 2.3444 - val_acc: 0.5712\n",
            "Epoch 144/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0458 - acc: 0.9871 - val_loss: 2.3596 - val_acc: 0.5681\n",
            "Epoch 145/180\n",
            "25838/25838 [==============================] - 3s 113us/step - loss: 0.0469 - acc: 0.9868 - val_loss: 2.3347 - val_acc: 0.5552\n",
            "Epoch 146/180\n",
            "25838/25838 [==============================] - 3s 113us/step - loss: 0.0437 - acc: 0.9875 - val_loss: 2.4501 - val_acc: 0.5618\n",
            "Epoch 147/180\n",
            "25838/25838 [==============================] - 3s 113us/step - loss: 0.0432 - acc: 0.9877 - val_loss: 2.3565 - val_acc: 0.5670\n",
            "Epoch 148/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0431 - acc: 0.9886 - val_loss: 2.4723 - val_acc: 0.5629\n",
            "Epoch 149/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0411 - acc: 0.9885 - val_loss: 2.3893 - val_acc: 0.5670\n",
            "Epoch 150/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0420 - acc: 0.9884 - val_loss: 2.4267 - val_acc: 0.5639\n",
            "Epoch 151/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0430 - acc: 0.9870 - val_loss: 2.3968 - val_acc: 0.5677\n",
            "Epoch 152/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0391 - acc: 0.9888 - val_loss: 2.4416 - val_acc: 0.5643\n",
            "Epoch 153/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0414 - acc: 0.9887 - val_loss: 2.4714 - val_acc: 0.5608\n",
            "Epoch 154/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0392 - acc: 0.9890 - val_loss: 2.4319 - val_acc: 0.5629\n",
            "Epoch 155/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0394 - acc: 0.9888 - val_loss: 2.4625 - val_acc: 0.5650\n",
            "Epoch 156/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0377 - acc: 0.9901 - val_loss: 2.4777 - val_acc: 0.5569\n",
            "Epoch 157/180\n",
            "25838/25838 [==============================] - 3s 113us/step - loss: 0.0356 - acc: 0.9896 - val_loss: 2.4114 - val_acc: 0.5639\n",
            "Epoch 158/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0368 - acc: 0.9899 - val_loss: 2.3857 - val_acc: 0.5698\n",
            "Epoch 159/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.0338 - acc: 0.9904 - val_loss: 2.5068 - val_acc: 0.5576\n",
            "Epoch 160/180\n",
            "25838/25838 [==============================] - 3s 116us/step - loss: 0.0366 - acc: 0.9893 - val_loss: 2.4793 - val_acc: 0.5604\n",
            "Epoch 161/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0353 - acc: 0.9899 - val_loss: 2.5093 - val_acc: 0.5556\n",
            "Epoch 162/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0366 - acc: 0.9893 - val_loss: 2.4659 - val_acc: 0.5622\n",
            "Epoch 163/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0364 - acc: 0.9902 - val_loss: 2.4767 - val_acc: 0.5601\n",
            "Epoch 164/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0349 - acc: 0.9906 - val_loss: 2.5435 - val_acc: 0.5594\n",
            "Epoch 165/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0337 - acc: 0.9909 - val_loss: 2.5194 - val_acc: 0.5611\n",
            "Epoch 166/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0324 - acc: 0.9908 - val_loss: 2.4716 - val_acc: 0.5580\n",
            "Epoch 167/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0346 - acc: 0.9903 - val_loss: 2.5826 - val_acc: 0.5587\n",
            "Epoch 168/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0320 - acc: 0.9916 - val_loss: 2.5665 - val_acc: 0.5601\n",
            "Epoch 169/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0332 - acc: 0.9914 - val_loss: 2.5453 - val_acc: 0.5590\n",
            "Epoch 170/180\n",
            "25838/25838 [==============================] - 3s 113us/step - loss: 0.0333 - acc: 0.9908 - val_loss: 2.5612 - val_acc: 0.5653\n",
            "Epoch 171/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0323 - acc: 0.9909 - val_loss: 2.4990 - val_acc: 0.5531\n",
            "Epoch 172/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0308 - acc: 0.9912 - val_loss: 2.5058 - val_acc: 0.5601\n",
            "Epoch 173/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0313 - acc: 0.9909 - val_loss: 2.5325 - val_acc: 0.5604\n",
            "Epoch 174/180\n",
            "25838/25838 [==============================] - 3s 115us/step - loss: 0.0317 - acc: 0.9917 - val_loss: 2.5567 - val_acc: 0.5615\n",
            "Epoch 175/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0293 - acc: 0.9915 - val_loss: 2.5360 - val_acc: 0.5601\n",
            "Epoch 176/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0298 - acc: 0.9915 - val_loss: 2.5885 - val_acc: 0.5657\n",
            "Epoch 177/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0302 - acc: 0.9915 - val_loss: 2.5993 - val_acc: 0.5632\n",
            "Epoch 178/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0299 - acc: 0.9917 - val_loss: 2.6447 - val_acc: 0.5618\n",
            "Epoch 179/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0284 - acc: 0.9921 - val_loss: 2.5861 - val_acc: 0.5677\n",
            "Epoch 180/180\n",
            "25838/25838 [==============================] - 3s 114us/step - loss: 0.0303 - acc: 0.9914 - val_loss: 2.6931 - val_acc: 0.5590\n",
            "3589/3589 [==============================] - 0s 32us/step\n",
            "Loss: 2.704740289460653\n",
            "Accuracy: 0.5606018337873936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wwi7VjGK4SvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"model_0p56.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CiFRgE47ubNX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}